#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºè°±AIæµ‹è¯•ä»£ç 
éªŒè¯æ™ºè°±å¤§æ¨¡å‹APIæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
from dotenv import load_dotenv

# åŠ è½½.envæ–‡ä»¶
load_dotenv()

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from utils.llm_utils import create_client_from_env


def test_zhipu_connection():
    """æµ‹è¯•æ™ºè°±AIè¿æ¥"""
    print("=" * 60)
    print("æµ‹è¯•1ï¼šæ™ºè°±AIè¿æ¥")
    print("=" * 60)

    try:
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        api_key = os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("OPENAI_BASE_URL")
        model = os.getenv("OPENAI_MODEL")

        print(f"APIå¯†é’¥: {'*' * (len(api_key) - 8)}{api_key[-8:]}")
        print(f"APIåœ°å€: {base_url}")
        print(f"æ¨¡å‹: {model}")

        if not api_key:
            print("\nâœ— æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
            return False

        print("\nâœ“ ç¯å¢ƒå˜é‡é…ç½®æ­£ç¡®")
        return True

    except Exception as e:
        print(f"âœ— æ£€æŸ¥å¤±è´¥: {e}")
        return False


def test_simple_chat():
    """æµ‹è¯•ç®€å•å¯¹è¯"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•2ï¼šç®€å•å¯¹è¯")
    print("=" * 60)

    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = create_client_from_env()

        # æµ‹è¯•å¯¹è¯
        question = "ä½ å¥½ï¼è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹RAGæŠ€æœ¯ã€‚"
        print(f"\né—®é¢˜: {question}")

        answer = client.simple_chat(question, max_tokens=100)
        print(f"\nå›ç­”: {answer}")

        print("\nâœ“ ç®€å•å¯¹è¯æµ‹è¯•æˆåŠŸ")
        return True

    except Exception as e:
        print(f"âœ— å¯¹è¯å¤±è´¥: {e}")
        print("\nå¯èƒ½çš„åŸå› :")
        print("1. APIå¯†é’¥æ— æ•ˆ")
        print("2. APIåœ°å€é…ç½®é”™è¯¯")
        print("3. æ¨¡å‹åç§°ä¸æ­£ç¡®")
        print("4. ç½‘ç»œè¿æ¥é—®é¢˜")
        return False


def test_rag_generation():
    """æµ‹è¯•RAGç”Ÿæˆ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•3ï¼šRAGç”Ÿæˆ")
    print("=" * 60)

    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = create_client_from_env()

        # æµ‹è¯•RAGç”Ÿæˆ
        context = """
        RAGï¼ˆRetrieval-Augmented Generationï¼‰æ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„AIæŠ€æœ¯ã€‚
        å®ƒçš„å·¥ä½œæµç¨‹åŒ…æ‹¬ï¼šæ–‡æ¡£åŠ è½½ã€å‘é‡åŒ–ã€æ£€ç´¢ã€ç”Ÿæˆå››ä¸ªæ­¥éª¤ã€‚
        RAGå¯ä»¥å‡å°‘å¤§æ¨¡å‹çš„å¹»è§‰é—®é¢˜ï¼Œæé«˜ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚
        """

        question = "RAGæŠ€æœ¯çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ"
        print(f"\nä¸Šä¸‹æ–‡: {context[:100]}...")
        print(f"\né—®é¢˜: {question}")

        answer = client.rag_generate(context, question, max_tokens=200)
        print(f"\nå›ç­”: {answer}")

        print("\nâœ“ RAGç”Ÿæˆæµ‹è¯•æˆåŠŸ")
        return True

    except Exception as e:
        print(f"âœ— RAGç”Ÿæˆå¤±è´¥: {e}")
        return False


def test_multi_turn_conversation():
    """æµ‹è¯•å¤šè½®å¯¹è¯"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•4ï¼šå¤šè½®å¯¹è¯")
    print("=" * 60)

    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = create_client_from_env()

        # ç¬¬ä¸€è½®
        print("\nç¬¬ä¸€è½®å¯¹è¯:")
        print("-" * 60)
        q1 = "ä»€ä¹ˆæ˜¯å‘é‡æ•°æ®åº“ï¼Ÿ"
        print(f"ç”¨æˆ·: {q1}")
        a1 = client.simple_chat(q1)
        print(f"åŠ©æ‰‹: {a1}")

        # ç¬¬äºŒè½®
        print("\nç¬¬äºŒè½®å¯¹è¯:")
        print("-" * 60)
        q2 = "å®ƒæœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ"
        print(f"ç”¨æˆ·: {q2}")
        a2 = client.simple_chat(q2)
        print(f"åŠ©æ‰‹: {a2}")

        print("\nâœ“ å¤šè½®å¯¹è¯æµ‹è¯•æˆåŠŸ")
        return True

    except Exception as e:
        print(f"âœ— å¤šè½®å¯¹è¯å¤±è´¥: {e}")
        return False


def test_temperature_control():
    """æµ‹è¯•æ¸©åº¦å‚æ•°æ§åˆ¶"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•5ï¼šæ¸©åº¦å‚æ•°æ§åˆ¶")
    print("=" * 60)

    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = create_client_from_env()

        question = "è¯·ç®€è¿°RAGæŠ€æœ¯ã€‚"

        # æµ‹è¯•ä¸åŒæ¸©åº¦
        temperatures = [0.0, 0.5, 1.0]

        for temp in temperatures:
            print(f"\næ¸©åº¦: {temp}")
            print("-" * 60)

            answer = client.simple_chat(
                question,
                temperature=temp,
                max_tokens=100
            )
            print(f"å›ç­”: {answer}")

        print("\nâœ“ æ¸©åº¦æ§åˆ¶æµ‹è¯•æˆåŠŸ")
        return True

    except Exception as e:
        print(f"âœ— æ¸©åº¦æ§åˆ¶å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("æ™ºè°±AIæµ‹è¯•å¥—ä»¶")
    print("=" * 60)

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("ç¯å¢ƒé…ç½®æ£€æŸ¥", test_zhipu_connection),
        ("ç®€å•å¯¹è¯", test_simple_chat),
        ("RAGç”Ÿæˆ", test_rag_generation),
        ("å¤šè½®å¯¹è¯", test_multi_turn_conversation),
        ("æ¸©åº¦æ§åˆ¶", test_temperature_control),
    ]

    results = []

    for test_name, test_func in tests:
        print(f"\nã€{test_name}ã€‘")
        success = test_func()
        results.append((test_name, success))

    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)

    passed = sum(1 for _, success in results if success)
    total = len(results)

    print(f"\né€šè¿‡: {passed}/{total}")

    for test_name, success in results:
        status = "âœ“ é€šè¿‡" if success else "âœ— å¤±è´¥"
        print(f"  {test_name}: {status}")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ™ºè°±AIé…ç½®æ­£ç¡®ã€‚")
    else:
        print("\nâš  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        print("\næ•…éšœæ’æŸ¥å»ºè®®:")
        print("1. æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„OPENAI_API_KEYæ˜¯å¦æ­£ç¡®")
        print("2. æ£€æŸ¥OPENAI_BASE_URLæ˜¯å¦ä¸º: https://open.bigmodel.cn/api/paas/v4/")
        print("3. æ£€æŸ¥OPENAI_MODELæ˜¯å¦ä¸º: glm-4-flash æˆ–å…¶ä»–æ™ºè°±æ¨¡å‹")
        print("4. ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸ï¼Œå¯ä»¥è®¿é—®æ™ºè°±AI API")
        print("5. æŸ¥çœ‹æ™ºè°±AIå®˜ç½‘: https://open.bigmodel.cn/")


if __name__ == "__main__":
    main()

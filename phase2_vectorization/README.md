#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
阶段二：数据处理与向量化
目标：掌握高质量数据处理和向量化方法
"""

"""
学习目标：
1. 掌握多格式文档解析技术
2. 实现文本清洗和标准化
3. 掌握多种文档分块策略
4. 深入理解Embedding模型
5. 搭建向量数据库

测试标准：
- 能解析PDF/HTML/Markdown/Word文档
- 分块质量提升30%以上
- 向量化准确率>95%
- 向量数据库CRUD操作流畅
- 批量向量化性能优化

关键技能：
- 文档解析器选择和使用
- 分块策略设计
- Embedding模型对比
- 向量数据库选型
- 批量处理优化
"""


# ==================== 1. 文档解析技术 ====================
"""
支持的文档格式：
1. PDF：pypdf, pdfplumber, PyPDF2
2. HTML：beautifulsoup4, lxml
3. Markdown：markdown
4. Word：python-docx
5. Excel：openpyxl, pandas
6. PowerPoint：python-pptx
7. TXT：内置open()

解析注意事项：
- 保留文档结构（标题、段落、列表等）
- 提取表格数据
- 处理图片（OCR）
- 保留元数据（作者、日期、来源）
"""


# ==================== 2. 文本清洗 ====================
"""
文本清洗步骤：
1. 去除特殊字符（保留中文、英文、数字、常用标点）
2. 统一空白字符（多个空格→一个空格）
3. 去除HTML标签（如果有）
4. 处理编码问题
5. 统一标点符号（全角/半角）

清洗原则：
- 保留语义信息
- 适度清洗，不过度
- 考虑Embedding模型的特性
- 保留必要的格式信息
"""


# ==================== 3. 文档分块策略 ====================
"""
策略1：固定大小分块（Fixed Size Chunking）
- 优点：简单易实现，计算效率高
- 缺点：可能切断语义，上下文丢失
- 适用：通用文档，对语义要求不高的场景
- 参数：chunk_size, chunk_overlap

策略2：语义分块（Semantic Chunking）
- 优点：保持语义完整性
- 缺点：计算复杂，需要额外模型
- 适用：长文档，需要保持语义的场景
- 方法：基于句子相似度、段落结构

策略3：基于结构的分块（Structure-based Chunking）
- 优点：保留文档逻辑结构
- 缺点：依赖文档格式
- 适用：结构化文档（Markdown、HTML）
- 方法：基于标题、段落、章节

策略4：递归分块（Recursive Chunking）
- 优点：灵活，适应性强
- 缺点：需要设计递归规则
- 适用：复杂文档，多层次结构

分块质量评估：
- 语义完整性（使用句子相似度）
- 信息完整性（关键信息是否保留）
- 上下文连贯性（Chunk之间的连贯性）

推荐策略：
- 短文档：固定大小分块
- 长文档：递归分块
- 结构化文档：基于结构的分块
- 高精度需求：语义分块
"""


# ==================== 4. Embedding模型对比 ====================
"""
模型选择标准：
1. 性能（准确率）
2. 速度（延迟）
3. 维度（存储成本）
4. 语言支持
5. 模型大小
6. 部署难度

主流模型对比：

OpenAI text-embedding-3-small:
- 维度：1536
- 语言：多语言
- 性能：高
- 速度：中（API调用）
- 优点：性能好，易用
- 缺点：依赖API，成本高
- 适用：生产环境，追求性能

OpenAI text-embedding-3-large:
- 维度：3072
- 语言：多语言
- 性能：很高
- 速度：慢（API调用）
- 优点：性能最好
- 缺点：成本高，速度慢
- 适用：高精度需求

sentence-transformers/all-MiniLM-L6-v2:
- 维度：384
- 语言：多语言
- 性能：中高
- 速度：快（本地部署）
- 优点：轻量，快速，免费
- 缺点：性能略低于OpenAI
- 适用：资源受限，快速原型

bge-large-en-v1.5:
- 维度：1024
- 语言：英文为主
- 性能：高
- 速度：中（本地部署）
- 优点：性能好，开源
- 缺点：仅支持英文
- 适用：英文场景

bge-large-zh-v1.5:
- 维度：1024
- 语言：中文
- 性能：高
- 速度：中（本地部署）
- 优点：中文性能好
- 缺点：仅支持中文
- 适用：中文场景

m3e-base:
- 维度：768
- 语言：中英双语
- 性能：中高
- 速度：中
- 优点：双语支持，开源
- 缺点：性能中等
- 适用：中英双语场景

推荐方案：
- 通用场景：OpenAI text-embedding-3-small
- 中文场景：bge-large-zh-v1.5
- 资源受限：all-MiniLM-L6-v2
- 高精度：text-embedding-3-large
"""


# ==================== 5. 向量数据库 ====================
"""
向量数据库选择标准：
1. 性能（查询速度）
2. 准确性（召回率）
3. 可扩展性（数据规模）
4. 易用性（部署难度）
5. 功能丰富度
6. 成本

主流向量数据库对比：

Chroma:
- 开源：是
- 性能：中
- 易用性：高
- 特点：简单易用，Python原生
- 适用：快速原型，小规模应用

FAISS:
- 开源：是
- 性能：高
- 易用性：中
- 特点：Facebook开发，高性能
- 适用：大规模检索，性能敏感场景

Pinecone:
- 开源：否
- 性能：高
- 易用性：高
- 特点：云服务，托管式
- 适用：生产环境，不想维护

Milvus:
- 开源：是
- 性能：高
- 易用性：中
- 特点：功能丰富，企业级
- 适用：企业级应用

Weaviate:
- 开源：是
- 性能：高
- 易用性：中高
- 特点：GraphQL API，模块化设计
- 适用：需要丰富功能的场景

推荐方案：
- 学习原型：Chroma
- 性能优化：FAISS
- 生产环境：Pinecone 或 Milvus
"""


# ==================== 6. 批量向量化优化 ====================
"""
优化策略：
1. 批量处理（Batch Processing）
   - 一次性处理多个文档
   - 减少API调用次数
   - 提高GPU利用率

2. 并行处理（Parallel Processing）
   - 多进程/多线程
   - 使用Joblib、concurrent.futures
   - 充分利用多核CPU

3. GPU加速（GPU Acceleration）
   - 使用CUDA
   - 支持的模型：sentence-transformers
   - 性能提升：5-10倍

4. 缓存机制（Caching）
   - 缓存已向量化的文档
   - 避免重复计算
   - 使用磁盘缓存

5. 增量更新（Incremental Update）
   - 只处理新文档
   - 减少重复工作
   - 提高效率

性能指标：
- 吞吐量（文档/秒）
- 延迟（毫秒）
- CPU/GPU使用率
- 内存占用

目标性能：
- 批量向量化：>1000文档/分钟（CPU）
- 批量向量化：>5000文档/分钟（GPU）
- 单个文档：<100ms
"""


# ==================== 7. 实践任务清单 ====================
"""
基础任务：
□ 2.1 实现PDF文档解析
□ 2.2 实现HTML/Markdown文档解析
□ 2.3 实现Word文档解析
□ 2.4 实现文本清洗函数
□ 2.5 实现固定大小分块
□ 2.6 实现语义分块
□ 2.7 实现递归分块
□ 2.8 对比分块策略质量
□ 2.9 对比多个Embedding模型
□ 2.10 搭建Chroma向量数据库
□ 2.11 实现向量CRUD操作
□ 2.12 实现批量向量化
□ 2.13 实现并行处理
□ 2.14 实现GPU加速（如果有GPU）
□ 2.15 实现缓存机制

进阶任务：
□ 2.16 实现文档去重
□ 2.17 实现元数据管理
□ 2.18 实现增量更新
□ 2.19 实现质量评估
□ 2.20 性能测试和优化

测试验证：
□ 2.21 解析准确率>95%
□ 2.22 分块质量提升30%
□ 2.23 向量化准确率>95%
□ 2.24 批量处理性能达标
□ 2.25 向量数据库响应<100ms

参考资料：
- LangChain文档: https://python.langchain.com/docs/modules/data_connection/document_loaders/
- ChromaDB文档: https://docs.trychroma.com/
- FAISS文档: https://faiss.ai/
- Sentence-Transformers: https://www.sbert.net/
"""

print("阶段二：数据处理与向量化")
print("=" * 60)
print("\n学习目标：")
print("1. 掌握多格式文档解析")
print("2. 实现高质量文本清洗")
print("3. 掌握多种分块策略")
print("4. 对比和选择Embedding模型")
print("5. 搭建向量数据库")

print("\n关键技术：")
print("- 文档解析器")
print("- 文本清洗")
print("- 分块策略")
print("- Embedding模型")
print("- 向量数据库")
print("- 批量处理")

print("\n实践任务：")
print("请参考本目录下的测试代码，完成所有任务")
print("注意对比不同策略的效果差异")
